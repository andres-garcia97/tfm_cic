{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0b4e1671892531c7f42accfb44082bb19c3b112f7857c036019b113172dd3e2c2",
   "display_name": "Python 3.9.5 64-bit ('tfm_cic': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "b4e1671892531c7f42accfb44082bb19c3b112f7857c036019b113172dd3e2c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exploratory Data Analysis \n",
    "\n",
    "## Performed on the energy network dataset, to verify outliers, distribution and meaningful graphs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sweetviz\n",
    "# conda install -c conda-forge lux-api\n",
    "\n",
    "# Specific libraries\n",
    "# import sweetviz as sv\n",
    "import autoviz\n",
    "# from autoviz.AutoViz_Class import AutoViz_Class\n",
    "import lux\n",
    "\n",
    "# General libraries\n",
    "import sys, os\n",
    "from os import system\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import timedelta"
   ]
  },
  {
   "source": [
    "### Part 0: Integrating the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "values_column_names = [\"time\", \"branch\" , \"organization\", \"substation\", \"transformer_code\", \"App SW\", \n",
    "                        \"V_L1\", \"I_L1\", \"W_L1\", \"QL_L1\", \"QC_L1\",\"cos_L1\", \"angle_L1\",\n",
    "                        \"V_L2\", \"I_L2\", \"W_L2\", \"QL_L2\", \"QC_L2\",\"cos_L2\", \"angle_L2\",\n",
    "                        \"V_L3\", \"I_L3\", \"W_L3\", \"QL_L3\", \"QC_L3\",\"cos_L3\", \"angle_L3\",\n",
    "                        \"temp_amb\",\n",
    "                        \"aplus_L1\", \"aminus_L1\", \"RplusL_L1\", \"RminusL_L1\", \"RplusC_L1\", \"RminusC_L1\", \n",
    "                        \"aplus_L2\", \"aminus_L2\", \"RplusL_L2\", \"RminusL_L2\", \"RplusC_L2\", \"RminusC_L2\",\n",
    "                        \"aplus_L3\", \"aminus_L3\", \"RplusL_L3\", \"RminusL_L3\", \"RplusC_L3\", \"RminusC_L3\"]\n",
    "\n",
    "script_path = os.getcwd()\n",
    "data = pd.read_csv('../DATA/LVSM_Def.csv',  sep = ';', header=0, names=values_column_names)\n",
    "\n",
    "# Cleaning data table\n",
    "data = data.drop([\"aminus_L1\", \"RminusL_L1\", \"RplusC_L1\", \n",
    "                  \"aminus_L2\", \"RminusL_L2\", \"RplusC_L2\",\n",
    "                  \"aminus_L3\", \"RminusL_L3\", \"RplusC_L3\"], axis=1)\n",
    "\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "# Change column types to appropiate\n",
    "data = data.astype({\"time\": str, \"branch\": str , \"organization\": str, \"substation\": str, \"transformer_code\": str, \"App SW\": str})\n",
    "\n",
    "data[[\"V_L1\", \"I_L1\", \"W_L1\", \"QL_L1\", \"QC_L1\",\"cos_L1\", \"angle_L1\",\n",
    "      \"V_L2\", \"I_L2\", \"W_L2\", \"QL_L2\", \"QC_L2\",\"cos_L2\", \"angle_L2\",\n",
    "      \"V_L3\", \"I_L3\", \"W_L3\", \"QL_L3\", \"QC_L3\",\"cos_L3\", \"angle_L3\",\n",
    "      \"temp_amb\"]] = data[[\"V_L1\", \"I_L1\", \"W_L1\", \"QL_L1\", \"QC_L1\",\"cos_L1\", \"angle_L1\",\n",
    "                           \"V_L2\", \"I_L2\", \"W_L2\", \"QL_L2\", \"QC_L2\",\"cos_L2\", \"angle_L2\",\n",
    "                           \"V_L3\", \"I_L3\", \"W_L3\", \"QL_L3\", \"QC_L3\",\"cos_L3\", \"angle_L3\",\n",
    "                           \"temp_amb\"]].astype(float)\n",
    "\n",
    "\n",
    "### Deal with the \"24:00\" problem. Adapt BOTH the hour and the day.\n",
    "# Get the indexes and replace hour\n",
    "for i, date in enumerate(data['time']):\n",
    "    if date.split()[1].split(':')[0] == '24':\n",
    "        data.loc[i, 'time'] = data.loc[i, 'time'].replace(\"24:00\",\"00:00\")\n",
    "        data.loc[i, 'time'] = pd.to_datetime(data.loc[i, 'time'], format = '%Y-%m-%d %H:%M') + timedelta(days = 1)\n",
    "\n",
    "# Update the format\n",
    "data['time'] = pd.to_datetime(data['time'], format = '%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the dataframe to split date and hour\n",
    "data_new = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleaning NA values from dataset\n",
      "Cleaning duplicate values from dataset\n"
     ]
    }
   ],
   "source": [
    "### Preformat\n",
    "\n",
    "# Split the time column into date and hour columns, for diagram's input preparation\n",
    "data_new['date'] = (data_new['time']).dt.date\n",
    "data_new['hour'] = (data_new['time']).dt.time\n",
    "\n",
    "# Delete the old time column\n",
    "data_new = data_new.drop([\"time\"], axis=1)\n",
    "\n",
    "# Put both columns at the start\n",
    "data_new = pd.concat([data_new['hour'], data_new.drop('hour',axis=1)], axis=1)\n",
    "data_new = pd.concat([data_new['date'], data_new.drop('date',axis=1)], axis=1)\n",
    "\n",
    "# Cleaning NA values\n",
    "if data_new.isna().sum().sum() < .10 * len(data_new): \n",
    "    print (\"Cleaning NA values from dataset\")\n",
    "    data_new = data_new.dropna()\n",
    "else:\n",
    "    raise Exception(\"Careful! Deleting NaN values would cut most of the dataset\")\n",
    "\n",
    "# Remove duplicates\n",
    "if data.duplicated().sum() < .10 * len(data_new): \n",
    "    print (\"Cleaning duplicate values from dataset\")\n",
    "    data_new = data_new.drop_duplicates(subset=['date', 'hour', 'substation', 'App SW'])\n",
    "else:\n",
    "    raise Exception(\"Careful! Deleting duplicated values would cut most of the dataset\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         date      hour branch organization substation transformer_code  \\\n0  2019-06-16  01:00:00     AE          SZZ       S201              TR1   \n1  2019-06-16  02:00:00     AE          SZZ       S201              TR1   \n2  2019-06-16  03:00:00     AE          SZZ       S201              TR1   \n3  2019-06-16  04:00:00     AE          SZZ       S201              TR1   \n4  2019-06-16  05:00:00     AE          SZZ       S201              TR1   \n\n  App SW   V_L1   I_L1     W_L1  ...  temp_amb  aplus_L1  RplusL_L1  \\\n0   003F  234.0   65.0  14964.0  ...      30.0   16082.0     1983.0   \n1   003F  233.0   57.0  13091.0  ...      29.0   14342.0     1441.0   \n2   003F  236.0   55.0  12847.0  ...      29.0   13543.0     1381.0   \n3   003F  234.0  135.0  30517.0  ...      29.0   20757.0     2954.0   \n4   003F  235.0  102.0  23069.0  ...      29.0   29753.0     5054.0   \n\n   RminusC_L1  aplus_L2  RplusL_L2  RminusC_L2  aplus_L3  RplusL_L3  \\\n0         0.0   16736.0     1620.0         0.0   23015.0     2179.0   \n1         0.0   14545.0     1057.0        28.0   23764.0     2906.0   \n2         0.0   14073.0     1141.0         0.0   22147.0     2942.0   \n3         0.0   22059.0     2021.0         0.0   27317.0     3701.0   \n4         0.0   31259.0     3121.0         2.0   33013.0     3778.0   \n\n   RminusC_L3  \n0         0.0  \n1         0.0  \n2         0.0  \n3         0.0  \n4         0.0  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hour</th>\n      <th>branch</th>\n      <th>organization</th>\n      <th>substation</th>\n      <th>transformer_code</th>\n      <th>App SW</th>\n      <th>V_L1</th>\n      <th>I_L1</th>\n      <th>W_L1</th>\n      <th>...</th>\n      <th>temp_amb</th>\n      <th>aplus_L1</th>\n      <th>RplusL_L1</th>\n      <th>RminusC_L1</th>\n      <th>aplus_L2</th>\n      <th>RplusL_L2</th>\n      <th>RminusC_L2</th>\n      <th>aplus_L3</th>\n      <th>RplusL_L3</th>\n      <th>RminusC_L3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-06-16</td>\n      <td>01:00:00</td>\n      <td>AE</td>\n      <td>SZZ</td>\n      <td>S201</td>\n      <td>TR1</td>\n      <td>003F</td>\n      <td>234.0</td>\n      <td>65.0</td>\n      <td>14964.0</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>16082.0</td>\n      <td>1983.0</td>\n      <td>0.0</td>\n      <td>16736.0</td>\n      <td>1620.0</td>\n      <td>0.0</td>\n      <td>23015.0</td>\n      <td>2179.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-06-16</td>\n      <td>02:00:00</td>\n      <td>AE</td>\n      <td>SZZ</td>\n      <td>S201</td>\n      <td>TR1</td>\n      <td>003F</td>\n      <td>233.0</td>\n      <td>57.0</td>\n      <td>13091.0</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>14342.0</td>\n      <td>1441.0</td>\n      <td>0.0</td>\n      <td>14545.0</td>\n      <td>1057.0</td>\n      <td>28.0</td>\n      <td>23764.0</td>\n      <td>2906.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-06-16</td>\n      <td>03:00:00</td>\n      <td>AE</td>\n      <td>SZZ</td>\n      <td>S201</td>\n      <td>TR1</td>\n      <td>003F</td>\n      <td>236.0</td>\n      <td>55.0</td>\n      <td>12847.0</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>13543.0</td>\n      <td>1381.0</td>\n      <td>0.0</td>\n      <td>14073.0</td>\n      <td>1141.0</td>\n      <td>0.0</td>\n      <td>22147.0</td>\n      <td>2942.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-06-16</td>\n      <td>04:00:00</td>\n      <td>AE</td>\n      <td>SZZ</td>\n      <td>S201</td>\n      <td>TR1</td>\n      <td>003F</td>\n      <td>234.0</td>\n      <td>135.0</td>\n      <td>30517.0</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>20757.0</td>\n      <td>2954.0</td>\n      <td>0.0</td>\n      <td>22059.0</td>\n      <td>2021.0</td>\n      <td>0.0</td>\n      <td>27317.0</td>\n      <td>3701.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-06-16</td>\n      <td>05:00:00</td>\n      <td>AE</td>\n      <td>SZZ</td>\n      <td>S201</td>\n      <td>TR1</td>\n      <td>003F</td>\n      <td>235.0</td>\n      <td>102.0</td>\n      <td>23069.0</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>29753.0</td>\n      <td>5054.0</td>\n      <td>0.0</td>\n      <td>31259.0</td>\n      <td>3121.0</td>\n      <td>2.0</td>\n      <td>33013.0</td>\n      <td>3778.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the train and test dataset\n",
    "msk = np.random.rand(len(data_new)) < 0.98\n",
    "\n",
    "df_train = data_new[msk]\n",
    "df_test = data_new[~msk]"
   ]
  },
  {
   "source": [
    "### Part 0: Automating EDA - Pandas methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.describe()"
   ]
  },
  {
   "source": [
    "### Part 1: Automating EDA - Using Sweetviz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis report\n",
    "analyze_report = sv.analyze(data_new)\n",
    "analyze_report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Train and Test Data Comparison - Differences and Similarities\n",
    "compare = sv.compare([df_train, \"Training Data\"], [df_test, \"Test Data\"], \"W_L1\")\n",
    "compare.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Done! Use 'show' commands to display/save.   |██████████| [100%]   00:04 -> (00:00 left)\n",
      "Report Compare_Intra.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# Create a Comparison - Particular column\n",
    "\n",
    "intra_com = sv.compare_intra(data_new[[\"date\", \"hour\", \"substation\", \"App SW\", \n",
    "                        \"V_L1\", \"I_L1\", \"W_L1\", \"QL_L1\", \"QC_L1\",\"cos_L1\", \"angle_L1\",\n",
    "                        \"V_L2\", \"I_L2\", \"W_L2\", \"QL_L2\", \"QC_L2\",\"cos_L2\", \"angle_L2\",\n",
    "                        \"V_L3\", \"I_L3\", \"W_L3\", \"QL_L3\", \"QC_L3\",\"cos_L3\", \"angle_L3\",\n",
    "                        \"temp_amb\"]], data_new[\"substation\"] == \"S242\", [\"S201\", \"S2274\", \"S242\", \"S286\", \"S287\", \"S406\", \"S480\", \"S499\", \"S531\", \"S612\", \"S68638\", \"S7116\", \"S733\", \"S740\", \"S744\", \"S76020\", \"S813\", \"S820\", \"S850\", \"S868\"])\n",
    "intra_com.show_html(filepath='Compare_Intra.html', open_browser=True, layout='widescreen', scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the info on the output cell, not the browser\n",
    "# report.show_notebook(w=None, h=None, scale=None,layout='widescreen',filepath=None)"
   ]
  },
  {
   "source": [
    "### Part 2: Automating EDA - Using Autoviz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'AutoViz_Class' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-acdec86a5dbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoViz_Class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoViz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../DATA/LVSM_Def.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AutoViz_Class' is not defined"
     ]
    }
   ],
   "source": [
    "AV = AutoViz_Class()\n",
    "\n",
    "df1 = AV.AutoViz('../DATA/LVSM_Def.xlsx')"
   ]
  },
  {
   "source": [
    "### Part 3: Automating EDA - Using Lux"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.intent = [\"I_L1\", \"W_L1\"]\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingVis = data_new.exported\n",
    "interestingVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingVis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.recommendation[\"Enhance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interestingVis[0].to_matplotlib())"
   ]
  },
  {
   "source": [
    "### Part 4: Filter useful info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"aminus_L1\", \"RminusL_L1\", \"RplusC_L1\", \n",
    "                  \"aminus_L2\", \"RminusL_L2\", \"RplusC_L2\",\n",
    "                  \"aminus_L3\", \"RminusL_L3\", \"RplusC_L3\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle a dataframe\n",
    "data.reindex(np.random.permutation(data.index))"
   ]
  }
 ]
}